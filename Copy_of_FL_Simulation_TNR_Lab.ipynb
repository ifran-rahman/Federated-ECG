{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ifran-rahman/Federated-ECG/blob/review/Copy_of_FL_Simulation_TNR_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pzZIp7SMevJr",
        "outputId": "62290f86-14a0-49b4-f04a-b12207652053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r4VHbKftKQvL"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# sys.path.append('client_train.py ')\n",
        "# sys.path.append('client.py')\n",
        "# sys.path.append('pre_n_post_process.py')\n",
        "# sys.path.append('server_train.py')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cfCqxJ3eFpLI"
      },
      "outputs": [],
      "source": [
        "# !pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "65Fny0CPHVek",
        "outputId": "64e5cce7-9ea0-4c0d-ae28-1ab3bd0ede3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (4.13.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install h5py\n",
        "!pip install typing-extensions\n",
        "!pip install wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YDlqzhG3bC4_",
        "outputId": "d44a0e1b-800d-4373-8ecb-86272843fc37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flwr[simulation] in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: cryptography<45.0.0,>=44.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (44.0.2)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.71.0)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (4.25.6)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (3.22.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (6.0.2)\n",
            "Requirement already satisfied: ray==2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.31.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (24.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr[simulation]) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (4.13.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.24.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U flwr[\"simulation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JfEWHYvNacM3"
      },
      "outputs": [],
      "source": [
        "# importing the module\n",
        "import tracemalloc\n",
        "\n",
        "import time\n",
        "\n",
        "# starting the monitoring\n",
        "tracemalloc.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mDwmU0E50VgP"
      },
      "outputs": [],
      "source": [
        "# we naturally first need to import torch and torchvision\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "from torchvision.datasets import MNIST\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn,optim\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def prepare__dataset(abnormal: pd.DataFrame, normal: pd.DataFrame, val_split_factor: float) -> tuple[torch.utils.data.Dataset, torch.utils.data.Dataset, dict]:\n",
        "    \"\"\"Prepares the training and validation datasets for ECG classification, shuffling the data before splitting.\n",
        "\n",
        "    Args:\n",
        "        abnormal (pd.DataFrame): DataFrame containing abnormal ECG data.\n",
        "        normal (pd.DataFrame): DataFrame containing normal ECG data.\n",
        "        val_split_factor (float): Fraction of the data to use for validation.\n",
        "\n",
        "    Returns:\n",
        "        tuple[torch.utils.data.Dataset, torch.utils.data.Dataset, dict]: A tuple containing the training dataset,\n",
        "            the validation dataset, and a dictionary with the number of examples in each.\n",
        "    \"\"\"\n",
        "    abnormal = abnormal.drop([187], axis=1)\n",
        "    normal = normal.drop([187], axis=1)\n",
        "\n",
        "    y_abnormal = np.ones((abnormal.shape[0]))\n",
        "    y_abnormal = pd.DataFrame(y_abnormal)\n",
        "\n",
        "    y_normal = np.zeros((normal.shape[0]))\n",
        "    y_normal = pd.DataFrame(y_normal)\n",
        "\n",
        "    x = pd.concat([abnormal, normal], sort=True)\n",
        "    y = pd.concat([y_abnormal, y_normal], sort=True)\n",
        "\n",
        "    x = x.to_numpy()\n",
        "    y = y[0].to_numpy()\n",
        "\n",
        "    # Create a TensorDataset before shuffling\n",
        "    full_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x).float(),\n",
        "                                                  torch.from_numpy(y).long())\n",
        "\n",
        "    # Calculate the lengths for training and validation sets\n",
        "    full_len = len(full_dataset)\n",
        "    val_len = int(full_len * val_split_factor)\n",
        "    train_len = full_len - val_len\n",
        "\n",
        "    # Shuffle the dataset using a random permutation of indices\n",
        "    indices = torch.randperm(full_len).tolist()\n",
        "    train_indices = indices[:train_len]\n",
        "    val_indices = indices[train_len:]\n",
        "\n",
        "    # Create SubsetRandomSamplers to get shuffled subsets\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
        "\n",
        "    # Create DataLoaders using the samplers\n",
        "    train_dataset = torch.utils.data.DataLoader(full_dataset, batch_size=train_len, sampler=train_sampler)\n",
        "    val_dataset = torch.utils.data.DataLoader(full_dataset, batch_size=val_len, sampler=val_sampler)\n",
        "\n",
        "    num_examples = {'trainset': train_len,\n",
        "                    'testset': val_len}\n",
        "\n",
        "    # Extract the datasets from the DataLoaders (since DataLoader returns iterators)\n",
        "    train_dataset = list(train_dataset)[0]\n",
        "    val_dataset = list(val_dataset)[0]\n",
        "\n",
        "    return train_dataset, val_dataset, num_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nOxp75kp0VgV"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "batch_size=500\n",
        "lr = 3e-3\n",
        "epochs = 21\n",
        "val_split_factor = 0.2\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a6rqQb0p0VgV"
      },
      "outputs": [],
      "source": [
        "root = '/content/drive/MyDrive/Federated-ECG/ECG_Classification/client/datasets/'\n",
        "# load dataset\n",
        "abnormal = pd.read_csv(root +'ptbdb_abnormal.csv', header = None)\n",
        "normal = pd.read_csv(root + 'ptbdb_normal.csv', header = None)\n",
        "\n",
        "train_dataset, val_dataset, _ = prepare__dataset(abnormal=abnormal, normal=normal, val_split_factor=val_split_factor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cMW7Z7Dtvjsf",
        "outputId": "e7447850-a696-4a98-a822-add68d8eb18a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10518"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(abnormal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6e-FhPHTjjOw",
        "outputId": "4917bae4-bc3c-416b-bce5-d32cf396d475"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((10518, 188), (4052, 188))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abnormal.shape, normal.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K0FySSU20VgW"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "#define the ecg_net model\n",
        "class ecg_net(nn.Module):\n",
        "\n",
        "    def __init__(self, num_of_class):\n",
        "        super(ecg_net, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(16, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(2944,500),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Linear(500, num_of_class),\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.model(x)\n",
        "        # print(x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #x [b, 2944]\n",
        "        # print(x.shape)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "27d5xeYm0VgW"
      },
      "outputs": [],
      "source": [
        "# def evalute(model, loader):\n",
        "#     model.eval()\n",
        "\n",
        "#     correct = 0\n",
        "#     total = len(loader)\n",
        "#     val_bar = tqdm(loader, file=sys.stdout)\n",
        "#     for x, y in val_bar:\n",
        "#         x, y = x.to(device), y.to(device)\n",
        "#         with torch.no_grad():\n",
        "#             logits = model(x)\n",
        "#             pred = logits.argmax(dim=1)\n",
        "#         correct += torch.eq(pred, y).sum().float().item()\n",
        "\n",
        "#     return correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6fqaAeM0VgX"
      },
      "source": [
        "## One Client, One Data Partition\n",
        "\n",
        "To start designing a Federated Learning pipeline we need to meet one of the key properties in FL: each client has its own data partition. To accomplish this with the dataset, we are going to generate N random partitions, where N is the total number of clients in our FL system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dewj-3te0VgZ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "def get_dataset(abnormal, normal, val_split_factor): # done\n",
        "\n",
        "    abnormal = abnormal.drop([187], axis=1)\n",
        "    normal = normal.drop([187], axis=1)\n",
        "\n",
        "    y_abnormal = np.ones((abnormal.shape[0]))\n",
        "    y_abnormal = pd.DataFrame(y_abnormal)\n",
        "\n",
        "    y_normal = np.zeros((normal.shape[0]))\n",
        "    y_normal = pd.DataFrame(y_normal)\n",
        "\n",
        "    x = pd.concat([abnormal, normal], sort=True)\n",
        "    y = pd.concat([y_abnormal, y_normal] ,sort=True)\n",
        "\n",
        "    x = x.to_numpy()\n",
        "    y = y[0].to_numpy()\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x).float(),\n",
        "                                                torch.from_numpy(y).long())\n",
        "\n",
        "    train_len = x.shape[0]\n",
        "    val_len = int(train_len * val_split_factor)\n",
        "    train_len -= val_len\n",
        "\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_len, val_len])\n",
        "\n",
        "    num_examples =  {'trainset': train_len,\n",
        "                    'testset': val_len}\n",
        "\n",
        "    return train_dataset, val_dataset, num_examples\n",
        "\n",
        "\n",
        "# define a Dataloader function\n",
        "def my_DataLoader(train_root, test_root, batch_size = 100, val_split_factor = 0.2):\n",
        "\n",
        "    train_df = pd.read_csv(train_root, header=None)\n",
        "    test_df = pd.read_csv(test_root, header=None)\n",
        "\n",
        "    train_data = train_df.to_numpy()\n",
        "    test_data = test_df.to_numpy()\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_data[:, :-1]).float(),\n",
        "                                                   torch.from_numpy(train_data[:, -1]).long(),)\n",
        "    test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(test_data[:, :-1]).float(),\n",
        "                                                  torch.from_numpy(test_data[:, -1]).long())\n",
        "\n",
        "    train_len = train_data.shape[0]\n",
        "    val_len = int(train_len * val_split_factor)\n",
        "    train_len -= val_len\n",
        "\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_len, val_len])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    num_examples =  {'trainset': train_len,\n",
        "                    'testset': val_len}\n",
        "\n",
        "\n",
        "    return train_loader, val_loader, test_loader, num_examples\n",
        "\n",
        "\n",
        "def prepare_dataset(num_partitions: int, batch_size: int, val_ratio: float = 0.1):\n",
        "    \"\"\"This function partitions the training set into N disjoint\n",
        "    subsets, each will become the local dataset of a client. This\n",
        "    function also subsequently partitions each training set partition\n",
        "    into train and validation. The test set is left intact and will\n",
        "    be used by the central server to asses the performance of the\n",
        "    global model.\"\"\"\n",
        "\n",
        "    # get the datatset\n",
        "    trainset, testset, _ = get_dataset(abnormal=abnormal, normal=normal, val_split_factor=val_split_factor)\n",
        "\n",
        "    print(len(trainset))\n",
        "    print(len(testset))\n",
        "    # split trainset into `num_partitions` trainsets\n",
        "    num_images = len(trainset) // num_partitions\n",
        "\n",
        "    partition_len = [num_images] * num_partitions\n",
        "\n",
        "    partition_len[len(partition_len)-1] = len(trainset)-sum(partition_len[:-1])\n",
        "    print(partition_len)\n",
        "    trainsets = random_split(\n",
        "        trainset, partition_len, torch.Generator().manual_seed(2023)\n",
        "    )\n",
        "\n",
        "    # create dataloaders with train+val support\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for trainset_ in trainsets:\n",
        "        num_total = len(trainset_)\n",
        "        num_val = int(val_ratio * num_total)\n",
        "        num_train = num_total - num_val\n",
        "\n",
        "        for_train, for_val = random_split(\n",
        "            trainset_, [num_train, num_val], torch.Generator().manual_seed(2023)\n",
        "        )\n",
        "        trainloaders.append(\n",
        "            DataLoader(for_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "        )\n",
        "        valloaders.append(\n",
        "            DataLoader(for_val, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "        )\n",
        "\n",
        "    # create dataloader for the test set\n",
        "    testloader = DataLoader(testset, batch_size=128)\n",
        "\n",
        "    datapoint_count = len(trainset[0][0])\n",
        "    print('Minimum DataPoint required for a signal :', datapoint_count)\n",
        "    return trainloaders, valloaders, testloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LhwlRNwt0Vga",
        "outputId": "84a2ba67-7b2a-4d39-b646-e3b150fdab59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11656\n",
            "2914\n",
            "[5828, 5828]\n",
            "Minimum DataPoint required for a signal : 187\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "NUM_CLIENTS = 2\n",
        "\n",
        "trainloaders, valloaders, testloader = prepare_dataset(num_partitions=NUM_CLIENTS, batch_size=20, val_ratio=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_-uR7NuQiPWG"
      },
      "outputs": [],
      "source": [
        "# !pip install -U flwr[\"simulation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X-p8mx5X0Vgb"
      },
      "outputs": [],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L0kKMJtzJE5M"
      },
      "outputs": [],
      "source": [
        "# !cp /content/drive/MyDrive/TNR\\ Lab/Federated-ECG/simulate_fl/client_train.py /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-A3fbcFFLTJw",
        "outputId": "3c16a55b-08a4-4b69-f041-402b0f4fd28f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cuda:0 device.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn,optim\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# define a Dataloader function\n",
        "def my_DataLoader(train_root, test_root, batch_size = 100, val_split_factor = 0.2):\n",
        "\n",
        "    train_df = pd.read_csv(train_root, header=None)\n",
        "    test_df = pd.read_csv(test_root, header=None)\n",
        "\n",
        "    train_data = train_df.to_numpy()\n",
        "    test_data = test_df.to_numpy()\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_data[:, :-1]).float(),\n",
        "                                                   torch.from_numpy(train_data[:, -1]).long(),)\n",
        "    test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(test_data[:, :-1]).float(),\n",
        "                                                  torch.from_numpy(test_data[:, -1]).long())\n",
        "\n",
        "    train_len = train_data.shape[0]\n",
        "    val_len = int(train_len * val_split_factor)\n",
        "    train_len -= val_len\n",
        "\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_len, val_len])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    num_examples =  {'trainset': train_len,\n",
        "                    'testset': val_len}\n",
        "\n",
        "\n",
        "    return train_loader, val_loader, test_loader, num_examples\n",
        "\n",
        "\n",
        "#define the ecg_net model\n",
        "class ecg_net(nn.Module):\n",
        "\n",
        "    def __init__(self, num_of_class):\n",
        "        super(ecg_net, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(16, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(2944,500),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Linear(500, num_of_class),\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.model(x)\n",
        "        # print(x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #x [b, 2944]\n",
        "        # print(x.shape)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# hyperparameters\n",
        "batch_size=1\n",
        "lr = 3e-3\n",
        "epochs = 10\n",
        "val_split_factor = 0.2\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"using {} device.\".format(device))\n",
        "\n",
        "def evaluate_model(model, loader, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    correct = 0\n",
        "    total = len(loader.dataset)\n",
        "    val_bar = tqdm(loader, file=sys.stdout)\n",
        "    for x, y in val_bar:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(dim=1)\n",
        "        correct += torch.eq(pred, y).sum().float().item()\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "def train_client(model, train_loader, valid_loader, epochs=1):\n",
        "\n",
        "    # model = ecg_net(2).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criteon = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_acc, best_epoch = 0, 0\n",
        "    global_step = 0\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, (x, y) in enumerate(train_bar):\n",
        "            # x: [b, 187], y: [b]\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            logits = model(x)\n",
        "            loss = criteon(logits, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # for param in model.parameters():\n",
        "            #     print(param.grad)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
        "                                                                     epochs,\n",
        "                                                                     loss)\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        if epoch % 1 == 0:  # You can change the validation frequency as you wish\n",
        "\n",
        "            val_acc = evalute(model, valid_loader)\n",
        "\n",
        "            print('val_acc = ',val_acc)\n",
        "            if val_acc > best_acc:\n",
        "                best_epoch = epoch\n",
        "                best_acc = val_acc\n",
        "\n",
        "                # torch.save(model.state_dict(), 'best_client_model.mdl')\n",
        "\n",
        "        print(\"Global steps\", global_step)\n",
        "\n",
        "    print('best acc:', best_acc, 'best epoch:', best_epoch)\n",
        "\n",
        "    # model.load_state_dict(torch.load('best.mdl'))\n",
        "    # print('loaded from ckpt!')\n",
        "\n",
        "# def validate(model, testloader, criterion):\n",
        "#     return 0,0\n",
        "def validate(model, testloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    device = next(model.parameters()).device  # Get model's current device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def prepare__dataset(abnormal, normal, val_split_factor):\n",
        "\n",
        "    abnormal = abnormal.drop([187], axis=1)\n",
        "    normal = normal.drop([187], axis=1)\n",
        "\n",
        "    y_abnormal = np.ones((abnormal.shape[0]))\n",
        "    y_abnormal = pd.DataFrame(y_abnormal)\n",
        "\n",
        "    y_normal = np.zeros((normal.shape[0]))\n",
        "    y_normal = pd.DataFrame(y_normal)\n",
        "\n",
        "    x = pd.concat([abnormal, normal], sort=True)\n",
        "    y = pd.concat([y_abnormal, y_normal] ,sort=True)\n",
        "\n",
        "    x = x.to_numpy()\n",
        "    y = y[0].to_numpy()\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x).float(),\n",
        "                                                torch.from_numpy(y).long())\n",
        "\n",
        "    train_len = x.shape[0]\n",
        "    val_len = int(train_len * val_split_factor)\n",
        "    train_len -= val_len\n",
        "\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_len, val_len])\n",
        "\n",
        "    num_examples =  {'trainset': train_len,\n",
        "                    'testset': val_len}\n",
        "\n",
        "    return train_dataset, val_dataset, num_examples\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # load dataset\n",
        "    abnormal = pd.read_csv('datasets/ptbdb_abnormal.csv', header = None)\n",
        "    normal = pd.read_csv('datasets/ptbdb_normal.csv', header = None)\n",
        "\n",
        "    train_dataset, val_dataset, _ = prepare__dataset(abnormal=abnormal, normal=normal, val_split_factor=val_split_factor)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = ecg_net(2).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criteon = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_acc, best_epoch = 0, 0\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, (x, y) in enumerate(train_bar):\n",
        "            # x: [b, 187], y: [b]\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            model.train()\n",
        "            logits = model(x)\n",
        "            loss = criteon(logits, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # for param in model.parameters():\n",
        "            #     print(param.grad)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
        "                                                                     epochs,\n",
        "                                                                     loss)\n",
        "            global_step += 1\n",
        "\n",
        "        if epoch % 1 == 0:  # You can change the validation frequency as you wish\n",
        "\n",
        "            val_acc = evalute(model, val_loader)\n",
        "\n",
        "            print('val_acc = ',val_acc)\n",
        "            if val_acc > best_acc:\n",
        "                best_epoch = epoch\n",
        "                best_acc = val_acc\n",
        "\n",
        "                torch.save(model.state_dict(), 'best.mdl')\n",
        "\n",
        "\n",
        "    print('best acc:', best_acc, 'best epoch:', best_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3ZRglKN_0Vgb"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Tuple\n",
        "import torch\n",
        "from flwr.common import NDArrays, Scalar\n",
        "# from client_train import *\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, trainloader, vallodaer) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = vallodaer\n",
        "        self.model = ecg_net(2)\n",
        "        # Determine device\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)  # send model to device\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"With the model paramters received from the server,\n",
        "        overwrite the uninitialise model in this class with them.\"\"\"\n",
        "\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        # now replace the parameters\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]):\n",
        "        \"\"\"Extract all model parameters and conver them to a list of\n",
        "        NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"This method train the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "\n",
        "        # copy parameters sent by the server into client's local model\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # read from config\n",
        "        lr = 0.001 # config[\"lr\"]\n",
        "        epochs = 5 #config[\"epochs\"]\n",
        "\n",
        "        # Define the optimizer\n",
        "        optim = torch.optim.SGD(self.model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "        # do local training\n",
        "        train_client(self.model, self.trainloader, self.valloader, epochs=epochs)\n",
        "\n",
        "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]) -> Tuple[float, int, Dict[str, Scalar]]:\n",
        "        \"\"\"Evaluate the model on the locally held dataset.\"\"\"\n",
        "\n",
        "        # Update local model with parameters received from the server\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # Get the loss criterion\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Switch the model to evaluation mode\n",
        "        self.model.eval()\n",
        "\n",
        "        # Disable gradient calculation during evaluation\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in self.valloader:\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate average loss and accuracy\n",
        "        avg_loss = total_loss / len(self.valloader)\n",
        "        accuracy = correct / total\n",
        "\n",
        "        # Return evaluation results\n",
        "        return avg_loss, total, {\"accuracy\": accuracy}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "97Rt0xHg0Vgd"
      },
      "outputs": [],
      "source": [
        "model = ecg_net(2).to(device=device)\n",
        "client = FlowerClient(trainloaders[0], valloaders[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4zD3gXi30Vge",
        "outputId": "28918454-f19c-46ea-c611-1dd21a00e381"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Metrics' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5ec03a9d1bec>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         }\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mweighted_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n\u001b[1;32m     78\u001b[0m     the client's evaluate() method.\"\"\"\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Metrics' is not defined"
          ]
        }
      ],
      "source": [
        "from typing import Dict, Optional, Tuple, List, Union\n",
        "from collections import OrderedDict\n",
        "import flwr as fl\n",
        "from flwr.common import (\n",
        "    Scalar,\n",
        ")\n",
        "\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    # Update model with the latest parameters\n",
        "    params_dict = zip(model.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for valloader in valloaders:  # Iterate through the list of validation loaders\n",
        "            for inputs, labels in valloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_correct += (predicted == labels).sum().item()\n",
        "                total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = total_correct / total_samples\n",
        "    return avg_loss, {\"accuracy\": accuracy}\n",
        "\n",
        "# You can now remove the separate 'validate' function as the logic is within 'evaluate'\n",
        "\n",
        "def get_evaluate_fn(testloader):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "    def evaluate_fn(\n",
        "        server_round: int,\n",
        "        parameters: fl.common.NDArrays,\n",
        "        config: Dict[str, fl.common.Scalar],\n",
        "        ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "        # Update model with the latest parameters\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss, accuracy = 0,0 #train.validate(model, test_loader, criterion)\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn\n",
        "\n",
        "    from flwr.common import Metrics\n",
        "\n",
        "def fit_config(server_round: int):\n",
        "        \"\"\"Return training configuration dict for each round.\n",
        "        Keep batch size fixed at 32, perform two rounds of training with one\n",
        "        local epoch, increase to two local epochs afterwards.\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            \"batch_size\": 1,\n",
        "            \"local_epochs\": 1 if server_round < 2 else 2,\n",
        "        }\n",
        "        return config\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
        "    the client's evaluate() method.\"\"\"\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
        "\n",
        "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
        "\n",
        "      def aggregate_fit(\n",
        "          self,\n",
        "          server_round: int,\n",
        "          results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
        "          failures: List[Union[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes], BaseException]],\n",
        "      ) -> Tuple[Optional[fl.common.Parameters], Dict[str, Scalar]]:\n",
        "\n",
        "          # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
        "          aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n",
        "\n",
        "          if aggregated_parameters is not None:\n",
        "\n",
        "              # Save aggregated_ndarrays\n",
        "              print(f\"Saving round {server_round} aggregated_ndarrays...\")\n",
        "\n",
        "              # Convert `Parameters` to `List[np.ndarray]`\n",
        "              aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
        "\n",
        "              np.savez(f\"round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
        "\n",
        "              # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
        "              params_dict = zip(model.state_dict().keys(), aggregated_ndarrays)\n",
        "              state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "              model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "              # Save the model\n",
        "              torch.save(model.state_dict(), f\"model_round_{server_round}.pth\")\n",
        "\n",
        "          return aggregated_parameters, aggregated_metrics\n",
        "\n",
        "strategy = SaveModelStrategy(\n",
        "        fraction_fit=1.0,\n",
        "        min_fit_clients=2,\n",
        "        min_available_clients=2,\n",
        "        evaluate_fn=evaluate,\n",
        "        on_fit_config_fn=fit_config,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LSickMd10Vgf"
      },
      "outputs": [],
      "source": [
        "def generate_client_fn(trainloaders, valloaders):\n",
        "    def client_fn(cid: str):\n",
        "        \"\"\"Returns a FlowerClient containing the cid-th data partition\"\"\"\n",
        "\n",
        "        return FlowerClient(\n",
        "            trainloader=trainloaders[int(cid)], vallodaer=valloaders[int(cid)]\n",
        "        )\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "\n",
        "client_fn_callback = generate_client_fn(trainloaders, valloaders)\n",
        "\n",
        "# With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# client needs exclusive access to these many resources in order to run\n",
        "client_resources = {\"num_cpus\": 1, \"num_gpus\": 1}\n",
        "\n",
        "start_training = time.time()\n",
        "x = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn_callback,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=3),\n",
        "    strategy=strategy,\n",
        "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1},\n",
        "    ray_init_args={\"log_to_driver\": False, \"num_cpus\": 1, \"num_gpus\": 1}\n",
        ")\n",
        "end_training = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5EPwlumGy6lH"
      },
      "outputs": [],
      "source": [
        "# displaying the memory\n",
        "print('Total Time', end_training - start_training)\n",
        "\n",
        "current, peak = tracemalloc.get_traced_memory()\n",
        "current_memory = current/(1024*1024)\n",
        "peak_memory = peak/(1024*1024)\n",
        "\n",
        "print('Current memory [MB]: {}, peak memory [MB]: {}'.format(current_memory, peak_memory))\n",
        "\n",
        "# stopping the library\n",
        "tracemalloc.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "McvAlMlfN4_r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}